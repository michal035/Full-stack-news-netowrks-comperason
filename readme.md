This is full stack project of that, which goal is to collect and analyze data collected from 2 very different popular news sites. Everyday headlines from 
both sides are collected and added to db. Data is analysed and, keywords are extracted and the summary is displayed on the site. 

Here is the pipeline - that's basically what's happening in .sh file
```
- scraping headlines from both sites
- filtering and cleaning headlines
- adding them to db

- getting keywords
- adding them to db

- final step - django - displaying data

```

Just quick demo to give you an idea what this is all about - this is older version of project

https://user-images.githubusercontent.com/84066345/223776951-6ffce02a-1373-4b28-90de-7761516bd086.mp4

List of technlogies used:
```
scraping - Scrapy
backend - Django
data analytics - Pandas
frontend - HTML/CSS/JS/Bootsrap
DataBase - Postgresql
```

Since i am planning on hosting this project some parts of code are left out for security purposes 
